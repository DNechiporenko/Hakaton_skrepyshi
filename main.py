# -*- coding: utf-8 -*-
"""Хакатон Скрепыши финальный вариант.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g8z1GMChL8tdUo78rsUVwUHhlitAaEfZ

Установка всех нужных библиотек для работы
"""

!pip install dash plotly pandas numpy flask
!pip install evaluate datasets transformers pandas numpy
!pip install rouge_score sacrebleu bert-score

"""Импорт нужных библиотек"""

import pandas as pd
import json
import evaluate
import os
import numpy as np

import dash
import dash_core_components as dcc
import dash_html_components as html
from dash.dependencies import Input, Output
import plotly.express as px
import plotly.colors as pc
from flask import Flask

"""Парсинг данных"""

from func_to_call import parse_all_data, parse_data_with_time

data_v1 = parse_all_data('/content/val_set.json')

data_v2 = parse_data_with_time('/content/val_set.json')

with open('parsed_tuning.json', 'w', encoding='utf-8') as f:
    json.dump(data_v1, f, ensure_ascii=False)

with open('parsed_dash.json', 'w', encoding='utf-8') as f:
    json.dump(data_v2, f, ensure_ascii=False)

with open('parsed_tuning.json', 'r', encoding='utf-8') as f:
    training_data = json.load(f)

formatted_data = []

for item in training_data:
    contexts = "\n".join([ctx['text'] for ctx in item['contexts']])
    base_input = f"Вопрос: {item['user_question']}\nКонтекст: {contexts}"

    if item['winner'] == 'Saiga':
        formatted_data.append({
            "input": base_input,
            "output": item['saiga_answer'],
            "source": "saiga",
            "rating": "good" if item['winner'] in ['Saiga', 'Оба хорошо'] else "bad"
        })

    elif item['winner'] == 'GigaChat':
        formatted_data.append({
            "input": base_input,
            "output": item['giga_answer'],
            "source": "giga",
            "rating": "good" if item['winner'] in ['GigaChat', 'Оба хорошо'] else "bad"
        })

    elif item['winner'] == 'Оба хорошо':
        formatted_data.extend([
            {
                "input": base_input,
                "output": item['saiga_answer'],
                "source": "saiga",
                "rating": "good"
            },
            {
                "input": base_input,
                "output": item['giga_answer'],
                "source": "giga",
                "rating": "good"
            }
        ])

    elif item['winner'] == 'Оба плохо':
        formatted_data.extend([
            {
                "input": base_input,
                "output": item['saiga_answer'],
                "source": "saiga",
                "rating": "bad"
            },
            {
                "input": base_input,
                "output": item['giga_answer'],
                "source": "giga",
                "rating": "bad"
            }
        ])

    else:
        formatted_data.append({
            "input": base_input,
            "output": item['saiga_answer'],
            "source": "unknown",
            "rating": "neutral"
        })

formatted_data[0]

DATA_FILE = "/content/train_set.json"
FIXED_DATA_FILE = "/content/val_set1.json"

with open(DATA_FILE, "r", encoding="utf-8") as f:
    df = pd.DataFrame(json.load(f))

df_melted = df.melt(id_vars=["Выбранная роль", "Кампус", "Уровень образования", "Категория вопроса",
                              "Вопрос пользователя", "Ресурсы для ответа", "Ответ AI"],
                     value_vars=["Saiga", "Giga"],
                     var_name="Модель", value_name="answer")


df_melted["Модель"] = df_melted["Модель"].replace({"Saiga": "Saiga", "Giga": "Gigachat"})

df_melted["ground_truth"] = df_melted["Ответ AI"]

df_melted["contexts"] = df_melted["Ресурсы для ответа"].apply(lambda x: [x] if isinstance(x, str) else x)

df_melted.to_json(FIXED_DATA_FILE, orient="records", force_ascii=False, indent=4)
print(f"Датасет исправлен и сохранен в {FIXED_DATA_FILE}")

"""Уменьшаем датасет, для более быстрого расчета метрик"""

original_data_path = "/content/val_set1.json"
reduced_data_path = "/content/train_set_reduced.json"

with open(original_data_path, "r", encoding="utf-8") as f:
    train_data = json.load(f)

df_train = pd.DataFrame(train_data)

df_sampled = df_train.sample(n=min(10, len(df_train)), random_state=42)

df_sampled.to_json(reduced_data_path, orient="records", force_ascii=False, indent=4)

reduced_data_path

"""Считаем метрики и записываем их в отдельный файл"""

BERT_MODEL = "distilbert-base-uncased"

rouge = evaluate.load("rouge")
bleu = evaluate.load("bleu")
bertscore = evaluate.load("bertscore")

DATA_FILE = "/content/train_set_reduced.json"
METRICS_FILE = "/content/model_metrics.json"

def safe_mean(values):
    return sum(values) / len(values) if values else 0.0

with open(DATA_FILE, "r", encoding="utf-8") as f:
    df = pd.DataFrame(json.load(f))

required_cols = ["Модель", "answer", "ground_truth", "contexts"]
if not all(col in df.columns for col in required_cols):
    print(f"В датасете не хватает колонок: {set(required_cols) - set(df.columns)}")
else:
    model_groups = df.groupby("Модель")
    #точность
    context_precisions = {}
    for model_name, model_data in model_groups:
        scores = []
        for _, row in model_data.iterrows():
            try:
                if row["contexts"]:
                    score = bleu.compute(
                        predictions=[row["answer"]],
                        references=row["contexts"],
                        max_order=2
                    )["precisions"][1]
                    scores.append(score)
            except Exception as e:
                print(f"Ошибка в context_precision: {e}")
        context_precisions[model_name] = safe_mean(scores)

    #релевантность
    relevances = {}
    for model_name, model_data in model_groups:
        scores = []
        for _, row in model_data.iterrows():
            try:
                if row["ground_truth"]:
                    score = rouge.compute(
                        predictions=[row["answer"]],
                        references=[row["ground_truth"]]
                    )["rouge2"]
                    scores.append(score)
            except Exception as e:
                print(f"Ошибка в relevance: {e}")
        relevances[model_name] = safe_mean(scores)

    #корректность
    correctness_scores = {}
    for model_name, model_data in model_groups:
        scores = []
        for _, row in model_data.iterrows():
            try:
                if row["ground_truth"]:
                    score = bertscore.compute(
                        predictions=[row["answer"]],
                        references=[row["ground_truth"]],
                        model_type=BERT_MODEL
                    )["f1"][0]
                    scores.append(score)
            except Exception as e:
                print(f"Ошибка в correctness: {e}")
        correctness_scores[model_name] = safe_mean(scores)

    model_metrics = {
        "Saiga": {
            "context_precision": context_precisions.get("Saiga", 0),
            "relevance": relevances.get("Saiga", 0),
            "correctness": correctness_scores.get("Saiga", 0),
        },
        "Gigachat": {
            "context_precision": context_precisions.get("Gigachat", 0),
            "relevance": relevances.get("Gigachat", 0),
            "correctness": correctness_scores.get("Gigachat", 0),
        }
    }

    with open(METRICS_FILE, "w", encoding="utf-8") as f:
        json.dump(model_metrics, f, indent=4, ensure_ascii=False)

    print(f"Метрики сохранены в {METRICS_FILE}")

"""Собираем все в один дэшборд"""

FULL_DATA_FILE = "/content/train_set.json"
METRICS_FILE = "/content/model_metrics.json"

def load_data(file_path):
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            return pd.DataFrame(json.load(f))
    return pd.DataFrame()


def load_metrics():
    if os.path.exists(METRICS_FILE):
        with open(METRICS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return None

server = Flask(__name__)
app = dash.Dash(__name__, server=server)


app.layout = html.Div(children=[
    html.H1("Мониторинг качества чат-бота", style={'textAlign': 'center'}),

    html.Button("Обновить данные", id="update-button", n_clicks=0),

    dcc.Graph(id="model-metrics"),

    dcc.Graph(id="campus-distribution"),
    dcc.Graph(id="category-distribution"),
    dcc.Graph(id="refinement-bar"),

    html.Div(id="response-time-output", style={"fontSize": "20px", "textAlign": "center", "marginTop": "20px"})
])

@app.callback(
    [
        Output("model-metrics", "figure"),
        Output("campus-distribution", "figure"),
        Output("category-distribution", "figure"),
        Output("refinement-bar", "figure"),
        Output("response-time-output", "children")
    ],
    [Input("update-button", "n_clicks")]
)
def update_dashboard(n_clicks):
    full_df = load_data(FULL_DATA_FILE)
    metrics = load_metrics()

    #визуализация метрик
    if metrics:
        df_metrics = pd.DataFrame([
            {"Модель": "Saiga", "context_precision": metrics["Saiga"]["context_precision"],
             "relevance": metrics["Saiga"]["relevance"], "correctness": metrics["Saiga"]["correctness"]},
            {"Модель": "Gigachat", "context_precision": metrics["Gigachat"]["context_precision"],
             "relevance": metrics["Gigachat"]["relevance"], "correctness": metrics["Gigachat"]["correctness"]}
        ])

        metrics_fig = px.bar(df_metrics.melt(id_vars="Модель"),
                             x="Модель", y="value", color="variable",
                             title="Сравнение моделей Saiga и Gigachat",
                             labels={"value": "Среднее значение метрики", "variable": "Метрика"},
                             barmode="group", color_discrete_sequence=pc.qualitative.Bold)
    else:
        metrics_fig = px.bar(title="Нет данных по метрикам")

    if not full_df.empty and "Кампус" in full_df.columns:
        campus_fig = px.bar(full_df["Кампус"].value_counts(),
                            title="Распределение пользователей по кампусам",
                            color=full_df["Кампус"].value_counts().index,
                            color_discrete_sequence=pc.qualitative.Vivid)
    else:
        campus_fig = px.bar(title="Нет данных о кампусах")

    if not full_df.empty and "Категория вопроса" in full_df.columns:
        category_fig = px.bar(full_df["Категория вопроса"].value_counts(),
                              title="Категории вопросов пользователей",
                              color=full_df["Категория вопроса"].value_counts().index,
                              color_discrete_sequence=pc.qualitative.Set2)
    else:
        category_fig = px.bar(title="Нет данных о категориях вопросов")

    if not full_df.empty and "Уточненный вопрос пользователя" in full_df.columns:
        num_refined = full_df["Уточненный вопрос пользователя"].notna().sum()
        num_no_refinement = len(full_df) - num_refined

        refinement_fig = px.bar(x=["Понравился ответ", "Уточняли вопрос"],
                                y=[num_no_refinement, num_refined],
                                title="Частота уточнённых вопросов",
                                color=["Понравился ответ", "Уточняли вопрос"],
                                color_discrete_sequence=pc.qualitative.Pastel)
    else:
        refinement_fig = px.bar(title="Нет данных по уточнённым вопросам")

    if "Время ответа модели (сек)" in full_df.columns:
        avg_response_time = full_df["Время ответа модели (сек)"].dropna().mean()
        response_time_text = f"Среднее время ответа модели: {avg_response_time:.2f} сек"
    else:
        response_time_text = "Нет данных"

    return metrics_fig, campus_fig, category_fig, refinement_fig, response_time_text

"""Запуск дэшборда"""

if __name__ == "__main__":
    app.run_server(debug=True, port=8050)