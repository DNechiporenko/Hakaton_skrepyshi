### Инструкция по запуску дашборда
Этот проект представляет собой дашборд для мониторинга качества чат-ботов Saiga и Gigachat. Данные анализируются и визуализируются с помощью Dash и Plotly.
(Мы реализовывали проект через рабочую среду Google Collab)

#### Шаги для запуска
1. Установите зависимости  
Запустите следующую команду, чтобы установить все нужные библиотеки:
   pip install dash plotly pandas numpy flask
   pip install evaluate datasets transformers
   pip install rouge_score sacrebleu bert-score
   
2. Запустите файл `main.py`  
Это автоматически:
   - Рассчитает метрики (`context_precision`, relevance, `correctness`) на маленьком датасете;
   - Запустит дашборд, который можно открыть в браузере.

### Описание проделанной работы
#### Цель проекта:  
Автоматизировать мониторинг качества чат-ботов через интерактивный дашборд.

Что мы сделали?
1. Визуализация пользовательских метрик:
- Распределение пользователей по кампусам
  
2. Визуализация метрик вопросов:
- Категории вопросов пользователей
- Частота уточненных вопросов
  
3. Подсчет и визуализация метрик качества:
- Context Precision: Точность использования контекста (BLEU)
- Relevance: Релевантность ответов (ROUGE)
- Correctness: Семантическая корректность (BERTScore)

Особенности:
Метрики в нашем проекте расчитываются на маленьком датасете, так как расчет на полном занимал достаточно много времени. Расчет на полном датасете следует производить на более больших мощностях.

### Какие еще метрики мы бы предложили использовать?

#### Дружелюбность (Politeness & Sentiment Score)  
Задача: Оценивать тональность ответа бота (негативная, нейтральная, позитивная).

Как считать:  
1. Использовать анализ тональности:  
   - Для русского — DeepPavlov/rubert-base-cased или LLaMA-2-7B-chat.  
   - Для английского — VADER, TextBlob, или DistilBERT Sentiment Analysis.  
2. Присваивать тональность ответу бота:  
   - Негативный (-1): содержит агрессию, грубость, сарказм.  
   - Нейтральный (0): вежливый, но сухой ответ.  
   - Позитивный (+1): дружелюбный, содержит благодарность или поддержку.  

#### Пример реализации:  
- Отправить ответ бота в модель анализа тональности и получить оценку.  
- Сохранить это значение в дашборде для мониторинга дружелюбности.  


#### Уверенность в ответе (Confidence Score)  
Задача: Оценивать, насколько бот уверен в своём ответе, и при низкой уверенности предлагать нейтральные или осторожные ответы, вместо выдачи потенциально ложной информации.  

Как считать Confidence Score?  
1. Использовать вероятности токенов  
   - Большинство LLM (GPT, BERT, T5) предсказывают следующий токен с некоторой вероятностью;
   - Если вероятность самого вероятного токена < 0.5, значит бот неуверен;
   - Если вероятность больше 0.8, значит бот уверен в своём ответе.  

2. Оценивать разницу между первым и вторым по вероятности предсказанными токенами  
   - Если разница > 0.3, бот уверен в своём ответе;
   - Если разница < 0.1, значит возможны несколько равнозначных ответов, и бот должен быть осторожным.  

3. Фильтровать "сомнительные" ответы  
   - Если бот использует слова "наверное", "возможно", "может быть", снизить confidence score; 
   - Если в ответе есть слова "точно", "без сомнений", но вероятность < 0.5 → флаг "необоснованная уверенность".  

4. Использовать специализированные модели  
   - Можно использовать модель BERT-based NLI (Natural Language Inference), чтобы оценивать, насколько ответ согласуется с вопросом;
   - Если модель предсказывает "неопределённость", снизить confidence score.  


### Как можно реализовать?  
1. Добавить эвристику по словам  
   - Проанализировать ответ на наличие неуверенных выражений (`"может быть", "кажется"`) и уменьшить confidence score.  
   - Если есть чрезмерно уверенные слова (`"определённо", "без сомнений"`) при низком Confidence Score → флаг "ложная уверенность".

2. Добавить проверку "знаний" модели  
   - Сравнивать ответ с базой знаний (Wikipedia, Knowledge Graph, RAG).  
   - Если ответ есть в базе, повышаем уверенность.  
   - Если в базе противоречие → ставим "неуверенность".  
